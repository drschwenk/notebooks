{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "* [Submitting HITs](#Submitting-HITs)\n",
    "\t* [Building URLs for images on s3](#Building-URLs-for-images-on-s3)\n",
    "\t* [submitting HITs in groups](#submitting-HITs-in-groups)\n",
    "* [Reviewing HITs](#Reviewing-HITs)\n",
    "* [Writing annotation results](#Writing-annotation-results)\n",
    "* [Ignore](#Ignore)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "from __future__ import division\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as st\n",
    "import itertools\n",
    "import math\n",
    "from collections import Counter, defaultdict\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import boto\n",
    "import json\n",
    "from copy import deepcopy\n",
    "import boto.mturk.connection as tc\n",
    "import boto.mturk.question as tq\n",
    "from boto.mturk.qualification import PercentAssignmentsApprovedRequirement, Qualifications, Requirement\n",
    "\n",
    "from keysTkingdom import mturk_ai2\n",
    "from keysTkingdom import aws_tokes\n",
    "\n",
    "import pdfextraction.amt_boto_modules as amt_util"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submitting HITs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building URLs for images on s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "book_groups,ranges = amt_util.load_book_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "daily_sci_urls = amt_util.make_book_group_urls(book_groups, 'daily_sci', ranges)\n",
    "spectrum_sci_urls = amt_util.make_book_group_urls(book_groups, 'spectrum_sci', ranges)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## submitting HITs in groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[$10,000.00]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sandbox_host = 'mechanicalturk.sandbox.amazonaws.com' \n",
    "mturk = tc.MTurkConnection(\n",
    "    aws_access_key_id = aws_tokes.access_key,\n",
    "    aws_secret_access_key = aws_tokes.access_secret_key,\n",
    "    host = sandbox_host,\n",
    "    debug = 1 # debug = 2 prints out all requests.\n",
    ")\n",
    "mturk.get_account_balance() # a reminder of sandbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "static_params = {\n",
    "    'title': \"Annotate Science Textbook\",\n",
    "    'description': \"Choose which category text from a grade-school science book best belongs to\",\n",
    "    'keywords': ['image', 'science', 'text', 'labeling' ],\n",
    "    'frame_height': 800,\n",
    "    'amount': 0.04,\n",
    "    'duration': 3600 * 24 *3,\n",
    "    'max_assignments': 2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "amt_util.create_hits_from_pages(mturk, daily_sci_urls[700:702], static_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "amt_util.delete_all_hits(mturk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reviewing HITs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "there are 1100 pages from daily science"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "r_hits = amt_util.get_completed_hits(mturk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<boto.mturk.connection.HIT at 0x10d1b12d0>,\n",
       " <boto.mturk.connection.HIT at 0x1092bd290>]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_hits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "assignment_results = amt_util.get_assignments(mturk, r_hits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "raw_hit_results = amt_util.process_raw_hits(assignment_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# amt_util.accept_hits(mturk, assignment_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results_df = amt_util.make_results_df(raw_hit_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page</th>\n",
       "      <th>category</th>\n",
       "      <th>hit_id</th>\n",
       "      <th>assignment_id</th>\n",
       "      <th>box_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Daily_Science_Grade_4_Evan_Moor_159.jpeg</td>\n",
       "      <td>Discussion</td>\n",
       "      <td>3SR6AEG6W5UEEFKDA71U2ZF6UG2YH0</td>\n",
       "      <td>3A4TN5196KJ4YWH24HO7USI4BZ2HCV</td>\n",
       "      <td>T14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Daily_Science_Grade_4_Evan_Moor_159.jpeg</td>\n",
       "      <td>unlabeled</td>\n",
       "      <td>3SR6AEG6W5UEEFKDA71U2ZF6UG2YH0</td>\n",
       "      <td>3A4TN5196KJ4YWH24HO7USI4BZ2HCV</td>\n",
       "      <td>T15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       page    category  \\\n",
       "0  Daily_Science_Grade_4_Evan_Moor_159.jpeg  Discussion   \n",
       "1  Daily_Science_Grade_4_Evan_Moor_159.jpeg   unlabeled   \n",
       "\n",
       "                           hit_id                   assignment_id box_id  \n",
       "0  3SR6AEG6W5UEEFKDA71U2ZF6UG2YH0  3A4TN5196KJ4YWH24HO7USI4BZ2HCV    T14  \n",
       "1  3SR6AEG6W5UEEFKDA71U2ZF6UG2YH0  3A4TN5196KJ4YWH24HO7USI4BZ2HCV    T15  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grouped_by_page = results_df.groupby(['page', 'box_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "agg_res = grouped_by_page.agg(pd.DataFrame.mode)\n",
    "agg_res.drop(['assignment_id', 'page', 'box_id'], axis=1, inplace=True)\n",
    "agg_res = agg_res.fillna('Answer')\n",
    "agg_res = agg_res.reset_index()\n",
    "agg_res.drop('level_2', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page</th>\n",
       "      <th>box_id</th>\n",
       "      <th>category</th>\n",
       "      <th>hit_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Daily_Science_Grade_4_Evan_Moor_159.jpeg</td>\n",
       "      <td>T1</td>\n",
       "      <td>unlabeled</td>\n",
       "      <td>3SR6AEG6W5UEEFKDA71U2ZF6UG2YH0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Daily_Science_Grade_4_Evan_Moor_159.jpeg</td>\n",
       "      <td>T10</td>\n",
       "      <td>Answer</td>\n",
       "      <td>3SR6AEG6W5UEEFKDA71U2ZF6UG2YH0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       page box_id   category  \\\n",
       "0  Daily_Science_Grade_4_Evan_Moor_159.jpeg     T1  unlabeled   \n",
       "1  Daily_Science_Grade_4_Evan_Moor_159.jpeg    T10     Answer   \n",
       "\n",
       "                           hit_id  \n",
       "0  3SR6AEG6W5UEEFKDA71U2ZF6UG2YH0  \n",
       "1  3SR6AEG6W5UEEFKDA71U2ZF6UG2YH0  "
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_res.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "amt_util.write_results_df(agg_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "to_review = ['start_seq'] + list(pd.unique(agg_res['page']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "amt_util.review_results(to_review)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Choosing the right price for your HITs is crucial, and it can be tricky to figure out when you’re first starting. It’s here that those using Mechanical Turk as a digital sweatshop are separated from those using Mechanical Turk as fair and equitable way to employ of other people. Many turkers consider it unethical to pay under $0.10 per minute. This amount works out to a $6.00 hourly wage or the minimum wage in the US (though many states pay higher). Turkers specifically pay attention to price when determining whether or not a HIT is worth their time. As one turker said in a survey “…I figure a good task is one I can make 10 to 12 cents a minute on.” If you’re looking to get your HITs done quickly and have high-quality turkers work on them (and trust me, you are!) then you should make sure you pay your turkers fairly. If you want a quick rule of thumb it’s:\n",
    "\n",
    "Fair Pay = $0.10 x (Average Number Of Minutes Per Assignment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_api_endpoint = 'http://localhost:8080/api/review'\n",
    "payload = {'pages_to_review': str(annotation_results.keys())}\n",
    "headers = {'content-type': 'application/json'}\n",
    "requests.post(review_api_endpoint, data=json.dumps(payload), headers=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'batch_results_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-153-5968eb072469>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmost_common\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mgrouped_results_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_results_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Input.image_url'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mturk_response\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgrouped_results_df\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_response\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Answer.NumberOfItems'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'batch_results_df' is not defined"
     ]
    }
   ],
   "source": [
    "def most_common_strict(turk_responses_single_page):\n",
    "    \"\"\"\n",
    "    returns the consensus response of the three raw response strings for a given page\n",
    "    \"\"\"\n",
    "    most_common = turk_responses_single_page[1]['Answer.NumberOfItems'].mode()\n",
    "    if most_common.empty:\n",
    "        most_common = pd.Series(['NO AGREEMENT'])\n",
    "    return most_common\n",
    "\n",
    "grouped_results_df = batch_results_df.groupby('Input.image_url')\n",
    "for turk_response in grouped_results_df:\n",
    "    print(image_response[1]['Answer.NumberOfItems'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for hit in r_hits[30:42]:\n",
    "    assignments = mturk.get_assignments(hit.HITId)\n",
    "    for assignment in assignments:\n",
    "        print int((assignment.SubmitTime).split('-')[2].split('T')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'annotation_results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-155-1f679089a5f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mpage_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mannotation_results\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miteritems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0munaltered_annotations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mamt_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_local_annotation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpage_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mamt_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_annotation_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpage_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munaltered_annotations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'./ai2-vision-turk-data/textbook-annotation-test/test-annotations/'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpage_schema\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'annotation_results' is not defined"
     ]
    }
   ],
   "source": [
    "for page_name, results in annotation_results.iteritems():\n",
    "    unaltered_annotations = amt_util.load_local_annotation(page_name)\n",
    "    amt_util.process_annotation_results(page_name, results, unaltered_annotations, './ai2-vision-turk-data/textbook-annotation-test/test-annotations/', page_schema)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
