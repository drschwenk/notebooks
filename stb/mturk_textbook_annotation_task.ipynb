{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "* [Submitting HITs](#Submitting-HITs)\n",
    "\t* [Building URLs for images on s3](#Building-URLs-for-images-on-s3)\n",
    "\t* [submitting HITs in groups](#submitting-HITs-in-groups)\n",
    "* [Reviewing HITs](#Reviewing-HITs)\n",
    "* [Writing annotation results](#Writing-annotation-results)\n",
    "* [Ignore](#Ignore)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "from __future__ import division\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as st\n",
    "import itertools\n",
    "import math\n",
    "from collections import Counter, defaultdict\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import boto\n",
    "import json\n",
    "from copy import deepcopy\n",
    "import boto.mturk.connection as tc\n",
    "import boto.mturk.question as tq\n",
    "from boto.mturk.qualification import PercentAssignmentsApprovedRequirement, Qualifications, Requirement\n",
    "\n",
    "from keysTkingdom import mturk_ai2\n",
    "from keysTkingdom import aws_tokes\n",
    "\n",
    "import pdfextraction.amt_boto_modules as amt_util"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submitting HITs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building URLs for images on s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "book_groups,ranges = amt_util.load_book_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "daily_sci_urls = amt_util.make_book_group_urls(book_groups, 'daily_sci', ranges)\n",
    "spectrum_sci_urls = amt_util.make_book_group_urls(book_groups, 'spectrum_sci', ranges)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## submitting HITs in groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sandbox_host = 'mechanicalturk.sandbox.amazonaws.com' \n",
    "mturk = tc.MTurkConnection(\n",
    "    aws_access_key_id = aws_tokes.access_key,\n",
    "    aws_secret_access_key = aws_tokes.access_secret_key,\n",
    "    host = sandbox_host,\n",
    "    debug = 1 # debug = 2 prints out all requests.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "static_params = {\n",
    "    'title': \"Annotate Science Textbook\",\n",
    "    'description': \"Choose which category text from a grade-school science book best belongs to\",\n",
    "    'keywords': ['image', 'science' ],\n",
    "    'frame_height': 1000,\n",
    "    'amount': 0.03,\n",
    "    'duration': 3600 * 3,\n",
    "    'max_assignments': 3\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# amt_util.create_single_hit(mturk, daily_sci_urls[87], static_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "amt_util.create_hits_from_pages(mturk, daily_sci_urls[602:642], static_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "amt_util.delete_all_hits(mturk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reviewing HITs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "there are 1100 pages from daily science"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "r_hits = mturk.get_reviewable_hits(page_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "annotation_results = {}\n",
    "for hit in r_hits:\n",
    "    assignments = mturk.get_assignments(hit.HITId)\n",
    "    for assigment in assignments:\n",
    "#         print(assignment.SubmitTime)\n",
    "#         print int((assignment.SubmitTime).split('-')[2].split('T')[0])\n",
    "        for answers in assigment.answers:\n",
    "            annotation_results[answers[0].fields[0]] = answers[1].fields            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Writing annotation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import jsonschema\n",
    "import requests \n",
    "from pdfextraction.annotation_schema import page_schema\n",
    "from flask import request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_api_endpoint = 'http://localhost:8080/api/review'\n",
    "payload = {'pages_to_review': str(annotation_results.keys())}\n",
    "headers = {'content-type': 'application/json'}\n",
    "requests.post(review_api_endpoint, data=json.dumps(payload), headers=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "u'T21'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-99-ef7848f714a6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpage_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mannotation_results\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miteritems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0munaltered_annotations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_local_annotation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpage_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mprocess_annotation_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpage_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munaltered_annotations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'./test_results/'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpage_schema\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-96-b59c0eb65e0b>\u001b[0m in \u001b[0;36mprocess_annotation_results\u001b[0;34m(anno_page_name, turk_consensus_result, unannotated_page, annotations_folder, page_schema)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mturk_results_json\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mturk_consensus_result\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mturk_results_json\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0munannotated_page\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'category'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'category'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mvalidator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjsonschema\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDraft4Validator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpage_schema\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: u'T21'"
     ]
    }
   ],
   "source": [
    "for page_name, results in annotation_results.iteritems():\n",
    "    unaltered_annotations = lamt_util.load_local_annotation(page_name)\n",
    "    amt_util.process_annotation_results(page_name, results, unaltered_annotations, './test_results/', page_schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# batch_results_df = pd.read_csv(data_dir+results_csv)\n",
    "# print(batch_results_df.shape)\n",
    "# batch_results_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# grouped_results_df = batch_results_df.groupby('Input.image_url')\n",
    "# for image_response in grouped_results_df:\n",
    "#     print(image_response[1]['Answer.NumberOfItems'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Choosing the right price for your HITs is crucial, and it can be tricky to figure out when you’re first starting. It’s here that those using Mechanical Turk as a digital sweatshop are separated from those using Mechanical Turk as fair and equitable way to employ of other people. Many turkers consider it unethical to pay under $0.10 per minute. This amount works out to a $6.00 hourly wage or the minimum wage in the US (though many states pay higher). Turkers specifically pay attention to price when determining whether or not a HIT is worth their time. As one turker said in a survey “…I figure a good task is one I can make 10 to 12 cents a minute on.” If you’re looking to get your HITs done quickly and have high-quality turkers work on them (and trust me, you are!) then you should make sure you pay your turkers fairly. If you want a quick rule of thumb it’s:\n",
    "\n",
    "Fair Pay = $0.10 x (Average Number Of Minutes Per Assignment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def most_common_strict(turk_responses_single_page):\n",
    "    \"\"\"\n",
    "    returns the consensus response of the three raw response strings for a given page\n",
    "    \"\"\"\n",
    "    most_common = turk_responses_single_page[1]['Answer.NumberOfItems'].mode()\n",
    "    if most_common.empty:\n",
    "        most_common = pd.Series(['NO AGREEMENT'])\n",
    "    return most_common\n",
    "\n",
    "grouped_results_df = batch_results_df.groupby('Input.image_url')\n",
    "for turk_response in grouped_results_df:\n",
    "    print(image_response[1]['Answer.NumberOfItems'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "for hit in r_hits[30:42]:\n",
    "    assignments = mturk.get_assignments(hit.HITId)\n",
    "    for assignment in assignments:\n",
    "        print int((assignment.SubmitTime).split('-')[2].split('T')[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
